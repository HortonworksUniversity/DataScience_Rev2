{
 "metadata": {
  "name": "",
  "signature": "sha256:08ec086623d747c3b662d0fd384bd86da67cef027b6ca3f81022ad87b5d7adfc"
 },
 "nbformat": 3,
 "nbformat_minor": 0,
 "worksheets": [
  {
   "cells": [
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "from pyspark import SparkContext\n",
      "from pyspark.mllib.recommendation import ALS\n",
      "from numpy import array"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "data = sc.textFile(\"test.data\")\n",
      "ratings = data.map(lambda line: array([float(x) for x in line.split(',')]))\n",
      "ratings.take(10)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# Build the recommendation model using Alternating Least Squares\n",
      "model = ALS.train(ratings, 1, 20)\n",
      "model"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# Evaluate the model on training data\n",
      "testdata = ratings.map(lambda p: (int(p[0]), int(p[1])))\n",
      "predictions = model.predictAll(testdata).map(lambda r: ((r[0], r[1]), r[2]))\n",
      "ratesAndPreds = ratings.map(lambda r: ((r[0], r[1]), r[2])).join(predictions)\n",
      "MSE = ratesAndPreds.map(lambda r: (r[1][0] - r[1][1])**2).reduce(lambda x, y: x + y)/ratesAndPreds.count()\n",
      "print(\"Mean Squared Error = \" + str(MSE))"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [],
     "language": "python",
     "metadata": {},
     "outputs": []
    }
   ],
   "metadata": {}
  }
 ]
}
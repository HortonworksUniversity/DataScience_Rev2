{
 "metadata": {
  "name": "",
  "signature": "sha256:fd02ac5d9aba46155e308cc3916c121cecc1c250539c6b77ae1362a89861161b"
 },
 "nbformat": 3,
 "nbformat_minor": 0,
 "worksheets": [
  {
   "cells": [
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "#K-Means Clustering Demo"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Run the code a few times with different values of `k_clusters` (which is the value of `k`)"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "from time import time\n",
      "import numpy as np\n",
      "import pylab as pl\n",
      "\n",
      "from sklearn import metrics\n",
      "from sklearn.cluster import KMeans\n",
      "from sklearn.datasets import load_digits\n",
      "from sklearn.decomposition import PCA\n",
      "from sklearn.preprocessing import scale\n",
      "\n",
      "np.random.seed(42)\n",
      "\n",
      "digits = load_digits()\n",
      "data = scale(digits.data)\n",
      "\n",
      "n_samples, n_features = data.shape\n",
      "k_clusters = 10\n",
      "labels = digits.target\n",
      "\n",
      "sample_size = 300\n",
      "\n",
      "print(\"k_clusters: %d, \\t n_samples %d, \\t n_features %d\"\n",
      "      % (k_clusters, n_samples, n_features))\n",
      "\n",
      "\n",
      "print(79 * '_')\n",
      "print('% 9s' % 'init'\n",
      "      '    time  inertia    homo   compl  v-meas     ARI AMI  silhouette')\n",
      "\n",
      "\n",
      "def bench_k_means(estimator, name, data):\n",
      "    t0 = time()\n",
      "    estimator.fit(data)\n",
      "    print('% 9s   %.2fs    %i   %.3f   %.3f   %.3f   %.3f   %.3f    %.3f'\n",
      "          % (name, (time() - t0), estimator.inertia_,\n",
      "             metrics.homogeneity_score(labels, estimator.labels_),\n",
      "             metrics.completeness_score(labels, estimator.labels_),\n",
      "             metrics.v_measure_score(labels, estimator.labels_),\n",
      "             metrics.adjusted_rand_score(labels, estimator.labels_),\n",
      "             metrics.adjusted_mutual_info_score(labels,  estimator.labels_),\n",
      "             metrics.silhouette_score(data, estimator.labels_,\n",
      "                                      metric='euclidean',\n",
      "                                      sample_size=sample_size)))\n",
      "\n",
      "bench_k_means(KMeans(init='k-means++', n_clusters=k_clusters, n_init=10),\n",
      "              name=\"k-means++\", data=data)\n",
      "\n",
      "bench_k_means(KMeans(init='random', n_clusters=k_clusters, n_init=10),\n",
      "              name=\"random\", data=data)\n",
      "\n",
      "# in this case the seeding of the centers is deterministic, hence we run the\n",
      "# kmeans algorithm only once with n_init=1\n",
      "pca = PCA(n_components=k_clusters).fit(data)\n",
      "bench_k_means(KMeans(init=pca.components_, n_clusters=k_clusters, n_init=1),\n",
      "              name=\"PCA-based\",\n",
      "              data=data)\n",
      "print(79 * '_')\n",
      "\n",
      "###############################################################################\n",
      "# Visualize the results on PCA-reduced data\n",
      "\n",
      "reduced_data = PCA(n_components=2).fit_transform(data)\n",
      "kmeans = KMeans(init='k-means++', n_clusters=k_clusters, n_init=10)\n",
      "kmeans.fit(reduced_data)\n",
      "\n",
      "# Step size of the mesh. Decrease to increase the quality of the VQ.\n",
      "h = .02     # point in the mesh [x_min, m_max]x[y_min, y_max].\n",
      "\n",
      "# Plot the decision boundary. For that, we will assign a color to each\n",
      "x_min, x_max = reduced_data[:, 0].min() + 1, reduced_data[:, 0].max() - 1\n",
      "y_min, y_max = reduced_data[:, 1].min() + 1, reduced_data[:, 1].max() - 1\n",
      "xx, yy = np.meshgrid(np.arange(x_min, x_max, h), np.arange(y_min, y_max, h))\n",
      "\n",
      "# Obtain labels for each point in mesh. Use last trained model.\n",
      "Z = kmeans.predict(np.c_[xx.ravel(), yy.ravel()])\n",
      "\n",
      "# Put the result into a color plot\n",
      "Z = Z.reshape(xx.shape)\n",
      "pl.figure(1)\n",
      "pl.clf()\n",
      "pl.imshow(Z, interpolation='nearest',\n",
      "          extent=(xx.min(), xx.max(), yy.min(), yy.max()),\n",
      "          cmap=pl.cm.Paired,\n",
      "          aspect='auto', origin='lower')\n",
      "\n",
      "pl.plot(reduced_data[:, 0], reduced_data[:, 1], 'k.', markersize=2)\n",
      "# Plot the centroids as a white X\n",
      "centroids = kmeans.cluster_centers_\n",
      "pl.scatter(centroids[:, 0], centroids[:, 1],\n",
      "           marker='x', s=169, linewidths=3,\n",
      "           color='w', zorder=10)\n",
      "pl.title('K-means clustering on the digits dataset (PCA-reduced data)\\n'\n",
      "         'Centroids are marked with white cross')\n",
      "pl.xlim(x_min, x_max)\n",
      "pl.ylim(y_min, y_max)\n",
      "pl.xticks(())\n",
      "pl.yticks(())\n",
      "pl.show()"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    }
   ],
   "metadata": {}
  }
 ]
}